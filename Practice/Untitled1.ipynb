{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee9470e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:07:17.538136Z",
     "start_time": "2023-05-21T14:07:15.233141Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Gnan\\\\DA\\\\KMU\\\\Prediction-COVID-19')\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "from torch.optim.adam import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd8c74c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:10:36.728019Z",
     "start_time": "2023-05-21T14:10:36.699633Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion1 = nn.MSELoss()\n",
    "\n",
    "def criterion2(actual, predict):\n",
    "    \n",
    "    loss = 0\n",
    "    div = 0\n",
    "    \n",
    "    for i in range(7):\n",
    "        div += (i+1)\n",
    "    \n",
    "    for i in range(32):\n",
    "        \n",
    "        for j in range(7):\n",
    "            loss += (j+1) * (abs(actual[i][j] - predict[i][j]))\n",
    "              \n",
    "    loss /= div\n",
    "    loss /= 32\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "def criterion3(actual, predict):\n",
    "    \n",
    "    loss = 0\n",
    "    div = 0\n",
    "    \n",
    "    for i in range(7):\n",
    "        div += (i+1)**2\n",
    "    \n",
    "    for i in range(32):\n",
    "        \n",
    "        for j in range(7):\n",
    "            loss += ((j+1)**2) * ((actual[i][j] - predict[i][j])**2)\n",
    "               \n",
    "    loss /= div   \n",
    "    loss = loss**(1/2) \n",
    "    loss /= 32\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def mto(data):\n",
    "    \n",
    "    df = Prepare_df.processing(data, 'Date', 'alpha')\n",
    "    x = df.iloc[:, 0:]\n",
    "    y = df.iloc[:,:1]\n",
    "    x_ss, y_ms = Prepare_df.scailing(x, y)\n",
    "    x = x.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    x, y = Prepare_df.window_sliding(df, x, y, 60, 1)\n",
    "    x_ss, y_ms = Prepare_df.window_sliding(df, x_ss, y_ms, 60, 1)\n",
    "    x_train = x_ss[:800]\n",
    "    y_train = y_ms[:800]\n",
    "    x_test = x_ss[800:]\n",
    "    y_test = y_ms[800:]\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train, batch_size = batch_size, shuffle = False)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    n = len(train_loader)\n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for data in train_loader:\n",
    "            seq, target = data\n",
    "            out = model(seq)\n",
    "            loss = criterion(out, target)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        loss_list.append(running_loss/n)\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('epoch: %d loss: %.4f'%(epoch+1, running_loss/n))\n",
    "        \n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "                    \n",
    "                if loss_list[epoch-patience] < loss_list[epoch]:\n",
    "                    print('\\n Early Stopping / epoch: %d loss: %.4f'%(epoch+1, running_loss/n))\n",
    "                \n",
    "                    break\n",
    "    \n",
    "    train_predict = model(x_ss)\n",
    "    predicted = train_predict.cpu().data.numpy()\n",
    "    label_y = y_ms.cpu().data.numpy()\n",
    "    mape = 100 * np.mean(np.abs((label_y-predicted+1)/label_y+1))\n",
    "                         \n",
    "    return mape\n",
    "\n",
    "def mtm(data):\n",
    "    \n",
    "    df = Prepare_df.processing(data, 'Date', 'alpha')\n",
    "    x = df.iloc[:, 0:]\n",
    "    y = df.iloc[:,:1]\n",
    "    x_ss, y_ms = Prepare_df.scailing(x, y)\n",
    "    x = x.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    x, y = Prepare_df.window_sliding(df, x, y, 60, 7)\n",
    "    x_ss, y_ms = Prepare_df.window_sliding(df, x_ss, y_ms, 60, 7)\n",
    "    x_train = x_ss[:800]\n",
    "    y_train = y_ms[:800]\n",
    "    x_test = x_ss[800:]\n",
    "    y_test = y_ms[800:]\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train, batch_size = batch_size, shuffle = False)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    n = len(train_loader)\n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for data in train_loader:\n",
    "            seq, target = data\n",
    "            out = model(seq, target, 7, 0.5).to(device)\n",
    "            loss = criterion(out, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        loss_list.append(running_loss/n)\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('epoch: %d loss: %.6f'%(epoch+1, running_loss/n))\n",
    "        \n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "            \n",
    "                if loss_list[epoch-patience] < loss_list[epoch]:\n",
    "                    print('\\n Early Stopping / epoch: %d loss: %.4f'%(epoch+1, running_loss/n))\n",
    "                \n",
    "                    break\n",
    "                    \n",
    "    train_predict = model(x_ss, y_ms, 7, 0.5)\n",
    "    predicted = train_predict.cpu().data.numpy()\n",
    "    label_y = y_ms.cpu().data.numpy()\n",
    "    mape = 100 * np.mean(np.abs((true-pred)/true))\n",
    "                         \n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a01009f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:10:37.478796Z",
     "start_time": "2023-05-21T14:10:37.406961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>City</th>\n",
       "      <th>Susceptible</th>\n",
       "      <th>Infected</th>\n",
       "      <th>Dead</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535431</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>서울</td>\n",
       "      <td>3544282</td>\n",
       "      <td>25006</td>\n",
       "      <td>6383</td>\n",
       "      <td>5959761</td>\n",
       "      <td>0.258321</td>\n",
       "      <td>0.074782</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>서울</td>\n",
       "      <td>3541881</td>\n",
       "      <td>25537</td>\n",
       "      <td>6383</td>\n",
       "      <td>5961631</td>\n",
       "      <td>0.088766</td>\n",
       "      <td>0.026980</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>서울</td>\n",
       "      <td>3541039</td>\n",
       "      <td>25689</td>\n",
       "      <td>6384</td>\n",
       "      <td>5962320</td>\n",
       "      <td>0.376110</td>\n",
       "      <td>0.110631</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>서울</td>\n",
       "      <td>3537451</td>\n",
       "      <td>26432</td>\n",
       "      <td>6387</td>\n",
       "      <td>5965162</td>\n",
       "      <td>0.341943</td>\n",
       "      <td>0.103019</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>서울</td>\n",
       "      <td>3534098</td>\n",
       "      <td>27059</td>\n",
       "      <td>6390</td>\n",
       "      <td>5967885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1172 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date City  Susceptible  Infected  Dead  Recovered     alpha  \\\n",
       "0     2020-01-20   서울      9535432         0     0          0  0.000000   \n",
       "1     2020-01-21   서울      9535432         0     0          0  0.000000   \n",
       "2     2020-01-22   서울      9535432         0     0          0  0.000000   \n",
       "3     2020-01-23   서울      9535432         0     0          0  0.000000   \n",
       "4     2020-01-24   서울      9535431         1     0          0  0.000000   \n",
       "...          ...  ...          ...       ...   ...        ...       ...   \n",
       "1167  2023-04-01   서울      3544282     25006  6383    5959761  0.258321   \n",
       "1168  2023-04-02   서울      3541881     25537  6383    5961631  0.088766   \n",
       "1169  2023-04-03   서울      3541039     25689  6384    5962320  0.376110   \n",
       "1170  2023-04-04   서울      3537451     26432  6387    5965162  0.341943   \n",
       "1171  2023-04-05   서울      3534098     27059  6390    5967885  0.000000   \n",
       "\n",
       "          beta     gamma  \n",
       "0     0.000000  0.000000  \n",
       "1     0.000000  0.000000  \n",
       "2     0.000000  0.000000  \n",
       "3     0.000000  0.000000  \n",
       "4     0.000000  0.000000  \n",
       "...        ...       ...  \n",
       "1167  0.074782  0.000000  \n",
       "1168  0.026980  0.000039  \n",
       "1169  0.110631  0.000117  \n",
       "1170  0.103019  0.000113  \n",
       "1171  0.000000  0.000000  \n",
       "\n",
       "[1172 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Data/SIR_Origin/*.csv'\n",
    "dic_files = Load_files.load_files(path, -17, -15)\n",
    "data = dic_files['서울']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a60e909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:10:38.870307Z",
     "start_time": "2023-05-21T14:10:38.856345Z"
    }
   },
   "outputs": [],
   "source": [
    "criterions_list = [criterion1, criterion2, criterion3]\n",
    "learning_rates_list = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "patiences_list = [20, 80, 160, 10000]\n",
    "hidden_sizes_list = [8, 16, 32, 64]\n",
    "num_layers_list = [1, 2, 4, 8, 16]\n",
    "batch_sizes_list = [32, 64, 128, 256]\n",
    "dropout_list = [0, 0.25, 0.5]\n",
    "trainers_list = [mto, mtm]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4553f145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:10:39.555697Z",
     "start_time": "2023-05-21T14:10:39.457050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14400\n"
     ]
    }
   ],
   "source": [
    "Hyperparameter_dict = {}\n",
    "i = 0\n",
    "\n",
    "for lr in learning_rates_list:\n",
    "    for criterion in criterions_list:\n",
    "        for patience in patiences_list:\n",
    "            for num_layers in num_layers_list:\n",
    "                for batch_sizes in batch_sizes_list:\n",
    "                    for hidden_size in hidden_sizes_list:    \n",
    "                        for dropout in dropout_list:\n",
    "                            Hyperparameter_dict[i] = [lr, criterion, patience, num_layers, batch_sizes, hidden_size, dropout]\n",
    "                            i += 1\n",
    "                        \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e71b648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:10:50.667298Z",
     "start_time": "2023-05-21T14:10:40.075176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(3, 8, batch_first=True)\n",
      "  (fc1): Linear(in_features=480, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Early Stopping / epoch: 61 loss: 0.0007\n",
      "inf\n",
      "RNN(\n",
      "  (rnn): RNN(3, 8, batch_first=True, dropout=0.25)\n",
      "  (fc1): Linear(in_features=480, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_8640\\2088827978.py:91: RuntimeWarning: divide by zero encountered in divide\n",
      "  mape = 100 * np.mean(np.abs((label_y-predicted+1)/label_y+1))\n",
      "C:\\Users\\PC\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "C:\\Users\\PC\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 36\u001b[0m\n\u001b[0;32m     31\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m---> 36\u001b[0m mape \u001b[38;5;241m=\u001b[39m \u001b[43mmto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(mape)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MAPE \u001b[38;5;241m>\u001b[39m mape:\n",
      "Cell \u001b[1;32mIn[7], line 75\u001b[0m, in \u001b[0;36mmto\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     73\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     74\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 75\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     77\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(running_loss\u001b[38;5;241m/\u001b[39mn)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\optim\\adam.py:307\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "MAPE = 0\n",
    "\n",
    "path = 'Data/SIR_Origin/*.csv'\n",
    "dic_files = Load_files.load_files(path, -17, -15)\n",
    "data = dic_files['서울']\n",
    "\n",
    "for i in range(len(Hyperparameter_dict)):\n",
    "        \n",
    "    lr = Hyperparameter_dict[i][0]\n",
    "    criterion = Hyperparameter_dict[i][1]\n",
    "    patience = Hyperparameter_dict[i][2]\n",
    "    num_layers = Hyperparameter_dict[i][3]\n",
    "    batch_size = Hyperparameter_dict[i][4]\n",
    "    hidden_size = Hyperparameter_dict[i][5]\n",
    "    dropout = Hyperparameter_dict[i][6]\n",
    "        \n",
    "    input_size = 3\n",
    "    sequence_length = 60\n",
    "    num_epochs = 10000\n",
    "    \n",
    "    model_RNN = RNN(input_size = input_size,\n",
    "                hidden_size = hidden_size,\n",
    "                sequence_length = sequence_length,\n",
    "                num_layers = num_layers, \n",
    "                dropout = dropout, \n",
    "                device = device).to(device)\n",
    "    \n",
    "    model = model_RNN\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr = lr)\n",
    "        \n",
    "\n",
    "    print(model)\n",
    "        \n",
    "    mape = mto(data)\n",
    "    print(mape)\n",
    "    if MAPE > mape:\n",
    "        MAPE = mape\n",
    "        models_dict[keys[k]] = [lr, criterion, patience, num_layers, batch_size, hidden_size, dropout, MAPE, loss_list, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19929f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f6632cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:06:47.571586Z",
     "start_time": "2023-05-21T14:06:47.525652Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "input_size = 3\n",
    "sequence_length = 60\n",
    "num_epochs = 10000\n",
    "optimizer = Adam(model.parameters(), lr = lr)\n",
    "\n",
    "model_RNN = RNN(input_size = input_size,\n",
    "                hidden_size = hidden_size,\n",
    "                sequence_length = sequence_length,\n",
    "                num_layers = num_layers, \n",
    "                dropout = dropout, \n",
    "                device = device).to(device)\n",
    "\n",
    "model_LSTM = LSTM(input_size = input_size,\n",
    "                  hidden_size = hidden_size,\n",
    "                  sequence_length = sequence_length,\n",
    "                  num_layers = num_layers, \n",
    "                  dropout = dropout, \n",
    "                  device = device).to(device)\n",
    "\n",
    "model_GRU = GRU(input_size = input_size,\n",
    "                hidden_size = hidden_size,\n",
    "                sequence_length = sequence_length,\n",
    "                num_layers = num_layers, \n",
    "                dropout = dropout, \n",
    "                device = device).to(device)\n",
    "\n",
    "model_BiRNN = BiRNN(input_size = input_size,\n",
    "                    hidden_size = hidden_size,\n",
    "                    sequence_length = sequence_length,\n",
    "                    num_layers = num_layers, \n",
    "                    dropout = dropout, \n",
    "                    device = device).to(device)\n",
    "\n",
    "model_BiLSTM = BiLSTM(input_size = input_size,\n",
    "                      hidden_size = hidden_size,\n",
    "                      sequence_length = sequence_length,\n",
    "                      num_layers = num_layers, \n",
    "                      dropout = dropout, \n",
    "                      device = device).to(device)\n",
    "\n",
    "model_BiGRU = BiGRU(input_size = input_size,\n",
    "                    hidden_size = hidden_size,\n",
    "                    sequence_length = sequence_length,\n",
    "                    num_layers = num_layers, \n",
    "                    dropout = dropout, \n",
    "                    device = device).to(device)\n",
    "\n",
    "model_seq2seq_RNN = RNN_encoder_decoder(input_size = input_size, \n",
    "                                        hidden_size = hidden_size,\n",
    "                                        num_layers = num_layers, \n",
    "                                        dropout = dropout,\n",
    "                                        device = device).to(device)\n",
    "\n",
    "model_seq2seq_LSTM = LSTM_encoder_decoder(input_size = input_size, \n",
    "                                         hidden_size = hidden_size,\n",
    "                                         num_layers = num_layers, \n",
    "                                         dropout = dropout,\n",
    "                                         device = device).to(device)\n",
    "\n",
    "model_seq2seq_GRU = GRU_encoder_decoder(input_size = input_size, \n",
    "                                        hidden_size = hidden_size,\n",
    "                                        num_layers = num_layers, \n",
    "                                        dropout = dropout,\n",
    "                                        device = device).to(device)\n",
    "\n",
    "model_seq2seq_BiRNN = BiRNN_encoder_decoder(input_size = input_size, \n",
    "                                            hidden_size = hidden_size,\n",
    "                                            num_layers = num_layers, \n",
    "                                            dropout = dropout,\n",
    "                                            device = device).to(device)\n",
    "\n",
    "model_seq2seq_BiLSTM = BiLSTM_encoder_decoder(input_size = input_size, \n",
    "                                              hidden_size = hidden_size,\n",
    "                                              num_layers = num_layers, \n",
    "                                              dropout = dropout,\n",
    "                                              device = device).to(device)\n",
    "\n",
    "model_seq2seq_BiGRU = BiGRU_encoder_decoder(input_size = input_size, \n",
    "                                            hidden_size = hidden_size,\n",
    "                                            num_layers = num_layers, \n",
    "                                            dropout = dropout,\n",
    "                                            device = device).to(device)\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "keys = ['RNN', 'LSTM', 'GRU', 'BiRNN', 'BiLSTM', 'BiGRU', \n",
    "        'seq2seq_RNN', 'seq2seq_LSTM', 'seq2seq_GRU', 'seq2seq_BiRNN', 'seq2seq_BiLSTM', 'seq2seq_BiGRU']\n",
    "\n",
    "models_list = [model_RNN, model_LSTM, model_GRU, \n",
    "              model_BiRNN, model_BiLSTM, model_BiGRU,\n",
    "              model_seq2seq_RNN, model_seq2seq_LSTM, model_seq2seq_GRU, \n",
    "              model_seq2seq_BiRNN, model_seq2seq_BiLSTM, model_seq2seq_BiGRU]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KDA_DA",
   "language": "python",
   "name": "kda_da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
