{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8ee9470e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:55:10.560404Z",
     "start_time": "2023-05-23T04:55:10.549435Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:\\\\Gnan\\\\DA\\\\KMU\\\\Prediction-COVID-19')\n",
    "from utils import *\n",
    "from model import *\n",
    "\n",
    "from torch.optim.adam import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3fd8c74c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:55:10.765904Z",
     "start_time": "2023-05-23T04:55:10.735464Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion1 = nn.MSELoss()\n",
    "\n",
    "def criterion2(actual, predict):\n",
    "    \n",
    "    loss = 0\n",
    "    div = 0\n",
    "    \n",
    "    for i in range(7):\n",
    "        div += (i+1)\n",
    "    \n",
    "    for i in range(32):\n",
    "        \n",
    "        for j in range(7):\n",
    "            loss += (j+1) * (abs(actual[i][j] - predict[i][j]))\n",
    "              \n",
    "    loss /= div\n",
    "    loss /= 32\n",
    "        \n",
    "    return loss\n",
    "\n",
    "\n",
    "def criterion3(actual, predict):\n",
    "    \n",
    "    loss = 0\n",
    "    div = 0\n",
    "    \n",
    "    for i in range(7):\n",
    "        div += (i+1)**2\n",
    "    \n",
    "    for i in range(32):\n",
    "        \n",
    "        for j in range(7):\n",
    "            loss += ((j+1)**2) * ((actual[i][j] - predict[i][j])**2)\n",
    "               \n",
    "    loss /= div   \n",
    "    loss = loss**(1/2) \n",
    "    loss /= 32\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def mto(data):\n",
    "    \n",
    "    df = Prepare_df.processing(data, 'Date', 'alpha')\n",
    "    x = df.iloc[:, 0:]\n",
    "    y = df.iloc[:,:1]\n",
    "    x_ss, y_ms = Prepare_df.scailing(x, y)\n",
    "    x = x.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    x, y = Prepare_df.window_sliding(df, x, y, 60, 1)\n",
    "    x_ss, y_ms = Prepare_df.window_sliding(df, x_ss, y_ms, 60, 1)\n",
    "    x_train = x_ss[:800]\n",
    "    y_train = y_ms[:800]\n",
    "    x_test = x_ss[800:]\n",
    "    y_test = y_ms[800:]\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train, batch_size = batch_size, shuffle = False)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    n = len(train_loader)\n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for data in train_loader:\n",
    "            seq, target = data\n",
    "            out = model(seq)\n",
    "            loss = criterion(out, target)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        loss_list.append(running_loss/n)\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('epoch: %d loss: %.4f'%(epoch+1, running_loss/n))\n",
    "        \n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "                    \n",
    "                if loss_list[epoch-patience] < loss_list[epoch]:\n",
    "                    print('\\n Early Stopping / epoch: %d loss: %.4f'%(epoch+1, running_loss/n))\n",
    "                \n",
    "                    break\n",
    "    \n",
    "    train_predict = model(x_ss)\n",
    "    predicted = train_predict.cpu().data.numpy()\n",
    "    label_y = y_ms.cpu().data.numpy()\n",
    "    \n",
    "    predicted = predicted.reshape(1110, 1)\n",
    "    predicted = ms.inverse_transform(predicted)\n",
    "    label_y = ms.inverse_transform(label_y)\n",
    "    \n",
    "    mape = 100 * np.mean(np.abs((label_y-predicted)/label_y))\n",
    "                         \n",
    "    return loss_list, predicted, label_y, mape\n",
    "\n",
    "def mtm(data):\n",
    "    \n",
    "    df = Prepare_df.processing(data, 'Date', 'alpha')\n",
    "    \n",
    "    x = df.iloc[:, 0:]\n",
    "    y = df.iloc[:,:1]\n",
    "    x_ss, y_ms = Prepare_df.scailing(x, y)\n",
    "    x = x.to_numpy()\n",
    "    y = y.to_numpy()\n",
    "    x, y = Prepare_df.window_sliding(df, x, y, 60, 7)\n",
    "    x_ss, y_ms = Prepare_df.window_sliding(df, x_ss, y_ms, 60, 7)\n",
    "    x_train = x_ss[:800]\n",
    "    y_train = y_ms[:800]\n",
    "    x_test = x_ss[800:]\n",
    "    y_test = y_ms[800:]\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = train, batch_size = batch_size, shuffle = False)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "    n = len(train_loader)\n",
    "    loss_list = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for data in train_loader:\n",
    "            seq, target = data\n",
    "            out = model(seq, target, 7, 0.5).to(device)\n",
    "            loss = criterion(out, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        loss_list.append(running_loss/n)\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('epoch: %d loss: %.6f'%(epoch+1, running_loss/n))\n",
    "        \n",
    "        if (epoch % patience == 0) & (epoch != 0):\n",
    "            \n",
    "                if loss_list[epoch-patience] < loss_list[epoch]:\n",
    "                    print('\\n Early Stopping / epoch: %d loss: %.4f'%(epoch+1, running_loss/n))\n",
    "                \n",
    "                    break\n",
    "                    \n",
    "    train_predict = model(x_ss, y_ms, 7, 0.5)\n",
    "    predicted = train_predict.cpu().data.numpy()\n",
    "    label_y = y_ms.cpu().data.numpy()\n",
    "    \n",
    "\n",
    "    \n",
    "    mape = 100 * np.mean(np.abs((true-pred)/true))\n",
    "                         \n",
    "    return loss_list, predicted, label_y, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a01009f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:55:11.569202Z",
     "start_time": "2023-05-23T04:55:11.490412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>City</th>\n",
       "      <th>Susceptible</th>\n",
       "      <th>Infected</th>\n",
       "      <th>Dead</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535431</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>서울</td>\n",
       "      <td>3544282</td>\n",
       "      <td>25006</td>\n",
       "      <td>6383</td>\n",
       "      <td>5959761</td>\n",
       "      <td>0.258321</td>\n",
       "      <td>0.074782</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>서울</td>\n",
       "      <td>3541881</td>\n",
       "      <td>25537</td>\n",
       "      <td>6383</td>\n",
       "      <td>5961631</td>\n",
       "      <td>0.088766</td>\n",
       "      <td>0.026980</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>서울</td>\n",
       "      <td>3541039</td>\n",
       "      <td>25689</td>\n",
       "      <td>6384</td>\n",
       "      <td>5962320</td>\n",
       "      <td>0.376110</td>\n",
       "      <td>0.110631</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>서울</td>\n",
       "      <td>3537451</td>\n",
       "      <td>26432</td>\n",
       "      <td>6387</td>\n",
       "      <td>5965162</td>\n",
       "      <td>0.341943</td>\n",
       "      <td>0.103019</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>서울</td>\n",
       "      <td>3534098</td>\n",
       "      <td>27059</td>\n",
       "      <td>6390</td>\n",
       "      <td>5967885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1172 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date City  Susceptible  Infected  Dead  Recovered     alpha  \\\n",
       "0     2020-01-20   서울      9535432         0     0          0  0.000000   \n",
       "1     2020-01-21   서울      9535432         0     0          0  0.000000   \n",
       "2     2020-01-22   서울      9535432         0     0          0  0.000000   \n",
       "3     2020-01-23   서울      9535432         0     0          0  0.000000   \n",
       "4     2020-01-24   서울      9535431         1     0          0  0.000000   \n",
       "...          ...  ...          ...       ...   ...        ...       ...   \n",
       "1167  2023-04-01   서울      3544282     25006  6383    5959761  0.258321   \n",
       "1168  2023-04-02   서울      3541881     25537  6383    5961631  0.088766   \n",
       "1169  2023-04-03   서울      3541039     25689  6384    5962320  0.376110   \n",
       "1170  2023-04-04   서울      3537451     26432  6387    5965162  0.341943   \n",
       "1171  2023-04-05   서울      3534098     27059  6390    5967885  0.000000   \n",
       "\n",
       "          beta     gamma  \n",
       "0     0.000000  0.000000  \n",
       "1     0.000000  0.000000  \n",
       "2     0.000000  0.000000  \n",
       "3     0.000000  0.000000  \n",
       "4     0.000000  0.000000  \n",
       "...        ...       ...  \n",
       "1167  0.074782  0.000000  \n",
       "1168  0.026980  0.000039  \n",
       "1169  0.110631  0.000117  \n",
       "1170  0.103019  0.000113  \n",
       "1171  0.000000  0.000000  \n",
       "\n",
       "[1172 rows x 9 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'Data/SIR_Origin/*.csv'\n",
    "dic_files = Load_files.load_files(path, -17, -15)\n",
    "data = dic_files['서울']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "175ee683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:55:12.025383Z",
     "start_time": "2023-05-23T04:55:12.008430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>City</th>\n",
       "      <th>Susceptible</th>\n",
       "      <th>Infected</th>\n",
       "      <th>Dead</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>서울</td>\n",
       "      <td>9535431</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>서울</td>\n",
       "      <td>3544282</td>\n",
       "      <td>25006</td>\n",
       "      <td>6383</td>\n",
       "      <td>5959761</td>\n",
       "      <td>0.258321</td>\n",
       "      <td>0.074782</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>2023-04-02</td>\n",
       "      <td>서울</td>\n",
       "      <td>3541881</td>\n",
       "      <td>25537</td>\n",
       "      <td>6383</td>\n",
       "      <td>5961631</td>\n",
       "      <td>0.088766</td>\n",
       "      <td>0.026980</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>2023-04-03</td>\n",
       "      <td>서울</td>\n",
       "      <td>3541039</td>\n",
       "      <td>25689</td>\n",
       "      <td>6384</td>\n",
       "      <td>5962320</td>\n",
       "      <td>0.376110</td>\n",
       "      <td>0.110631</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>2023-04-04</td>\n",
       "      <td>서울</td>\n",
       "      <td>3537451</td>\n",
       "      <td>26432</td>\n",
       "      <td>6387</td>\n",
       "      <td>5965162</td>\n",
       "      <td>0.341943</td>\n",
       "      <td>0.103019</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>2023-04-05</td>\n",
       "      <td>서울</td>\n",
       "      <td>3534098</td>\n",
       "      <td>27059</td>\n",
       "      <td>6390</td>\n",
       "      <td>5967885</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1172 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date City  Susceptible  Infected  Dead  Recovered     alpha  \\\n",
       "0     2020-01-20   서울      9535432         0     0          0  0.000001   \n",
       "1     2020-01-21   서울      9535432         0     0          0  0.000001   \n",
       "2     2020-01-22   서울      9535432         0     0          0  0.000001   \n",
       "3     2020-01-23   서울      9535432         0     0          0  0.000001   \n",
       "4     2020-01-24   서울      9535431         1     0          0  0.000001   \n",
       "...          ...  ...          ...       ...   ...        ...       ...   \n",
       "1167  2023-04-01   서울      3544282     25006  6383    5959761  0.258321   \n",
       "1168  2023-04-02   서울      3541881     25537  6383    5961631  0.088766   \n",
       "1169  2023-04-03   서울      3541039     25689  6384    5962320  0.376110   \n",
       "1170  2023-04-04   서울      3537451     26432  6387    5965162  0.341943   \n",
       "1171  2023-04-05   서울      3534098     27059  6390    5967885  0.000001   \n",
       "\n",
       "          beta     gamma  \n",
       "0     0.000000  0.000000  \n",
       "1     0.000000  0.000000  \n",
       "2     0.000000  0.000000  \n",
       "3     0.000000  0.000000  \n",
       "4     0.000000  0.000000  \n",
       "...        ...       ...  \n",
       "1167  0.074782  0.000000  \n",
       "1168  0.026980  0.000039  \n",
       "1169  0.110631  0.000117  \n",
       "1170  0.103019  0.000113  \n",
       "1171  0.000000  0.000000  \n",
       "\n",
       "[1172 rows x 9 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['alpha']== 0, 'alpha'] = 1e-6\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a60e909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:55:13.151420Z",
     "start_time": "2023-05-23T04:55:13.143447Z"
    }
   },
   "outputs": [],
   "source": [
    "criterions_list = [criterion1, criterion2, criterion3]\n",
    "learning_rates_list = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "patiences_list = [20, 80, 160, 10000]\n",
    "hidden_sizes_list = [8, 16, 32, 64]\n",
    "num_layers_list = [1, 2, 4, 8, 16]\n",
    "batch_sizes_list = [32, 64, 128, 256]\n",
    "dropout_list = [0, 0.25, 0.5]\n",
    "trainers_list = [mto, mtm]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4553f145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:55:13.694511Z",
     "start_time": "2023-05-23T04:55:13.668548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14400\n"
     ]
    }
   ],
   "source": [
    "Hyperparameter_dict = {}\n",
    "i = 0\n",
    "\n",
    "for lr in learning_rates_list:\n",
    "    for criterion in criterions_list:\n",
    "        for patience in patiences_list:\n",
    "            for num_layers in num_layers_list:\n",
    "                for batch_sizes in batch_sizes_list:\n",
    "                    for hidden_size in hidden_sizes_list:    \n",
    "                        for dropout in dropout_list:\n",
    "                            Hyperparameter_dict[i] = [lr, criterion, patience, num_layers, batch_sizes, hidden_size, dropout]\n",
    "                            i += 1\n",
    "                        \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e71b648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:55:23.919742Z",
     "start_time": "2023-05-23T04:55:18.894843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(3, 8, batch_first=True)\n",
      "  (fc1): Linear(in_features=480, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "\n",
      " Early Stopping / epoch: 61 loss: 0.0002\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 39\u001b[0m\n\u001b[0;32m     34\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m---> 39\u001b[0m a, b, c, mape \u001b[38;5;241m=\u001b[39m \u001b[43mmto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(mape)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MAPE \u001b[38;5;241m>\u001b[39m mape:\n",
      "Cell \u001b[1;32mIn[71], line 93\u001b[0m, in \u001b[0;36mmto\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     90\u001b[0m label_y \u001b[38;5;241m=\u001b[39m y_ms\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     92\u001b[0m predicted \u001b[38;5;241m=\u001b[39m predicted\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1110\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m predicted \u001b[38;5;241m=\u001b[39m \u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m label_y \u001b[38;5;241m=\u001b[39m ms\u001b[38;5;241m.\u001b[39minverse_transform(label_y)\n\u001b[0;32m     96\u001b[0m mape \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs((label_y\u001b[38;5;241m-\u001b[39mpredicted)\u001b[38;5;241m/\u001b[39mlabel_y))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:535\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;124;03m\"\"\"Undo the scaling of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;124;03m        Transformed data.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 535\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    538\u001b[0m         X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy, dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n\u001b[0;32m    541\u001b[0m     X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\sklearn\\utils\\validation.py:1380\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1375\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1376\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1377\u001b[0m     ]\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1380\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "MAPE = 0\n",
    "\n",
    "ms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "path = 'Data/SIR_Origin/*.csv'\n",
    "dic_files = Load_files.load_files(path, -17, -15)\n",
    "data = dic_files['서울']\n",
    "\n",
    "for i in range(len(Hyperparameter_dict)):\n",
    "        \n",
    "    lr = Hyperparameter_dict[i][0]\n",
    "    criterion = Hyperparameter_dict[i][1]\n",
    "    patience = Hyperparameter_dict[i][2]\n",
    "    num_layers = Hyperparameter_dict[i][3]\n",
    "    batch_size = Hyperparameter_dict[i][4]\n",
    "    hidden_size = Hyperparameter_dict[i][5]\n",
    "    dropout = Hyperparameter_dict[i][6]\n",
    "        \n",
    "    input_size = 3\n",
    "    sequence_length = 60\n",
    "    num_epochs = 10000\n",
    "    \n",
    "    model_RNN = RNN(input_size = input_size,\n",
    "                    hidden_size = hidden_size,\n",
    "                    sequence_length = sequence_length,\n",
    "                    num_layers = num_layers, \n",
    "                    dropout = dropout, \n",
    "                    device = device).to(device)\n",
    "    \n",
    "    model = model_RNN\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr = lr)\n",
    "        \n",
    "\n",
    "    print(model)\n",
    "        \n",
    "    a, b, c, mape = mto(data)\n",
    "    print(mape)\n",
    "    if MAPE > mape:\n",
    "        MAPE = mape\n",
    "        models_dict[keys[k]] = [lr, criterion, patience, num_layers, batch_size, hidden_size, dropout, MAPE, loss_list, model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d19929f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:53:44.894721Z",
     "start_time": "2023-05-23T04:53:44.876772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f8f9cdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:53:45.404409Z",
     "start_time": "2023-05-23T04:53:45.392440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6c8a03e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T04:53:54.649540Z",
     "start_time": "2023-05-23T04:53:54.633582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00980425],\n",
       "       [0.0066669 ],\n",
       "       [0.02245329],\n",
       "       ...,\n",
       "       [0.12537   ],\n",
       "       [0.11398092],\n",
       "       [0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f16897f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f6632cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T14:06:47.571586Z",
     "start_time": "2023-05-21T14:06:47.525652Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\envs\\KMU_DA\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "input_size = 3\n",
    "sequence_length = 60\n",
    "num_epochs = 10000\n",
    "optimizer = Adam(model.parameters(), lr = lr)\n",
    "\n",
    "model_RNN = RNN(input_size = input_size,\n",
    "                hidden_size = hidden_size,\n",
    "                sequence_length = sequence_length,\n",
    "                num_layers = num_layers, \n",
    "                dropout = dropout, \n",
    "                device = device).to(device)\n",
    "\n",
    "model_LSTM = LSTM(input_size = input_size,\n",
    "                  hidden_size = hidden_size,\n",
    "                  sequence_length = sequence_length,\n",
    "                  num_layers = num_layers, \n",
    "                  dropout = dropout, \n",
    "                  device = device).to(device)\n",
    "\n",
    "model_GRU = GRU(input_size = input_size,\n",
    "                hidden_size = hidden_size,\n",
    "                sequence_length = sequence_length,\n",
    "                num_layers = num_layers, \n",
    "                dropout = dropout, \n",
    "                device = device).to(device)\n",
    "\n",
    "model_BiRNN = BiRNN(input_size = input_size,\n",
    "                    hidden_size = hidden_size,\n",
    "                    sequence_length = sequence_length,\n",
    "                    num_layers = num_layers, \n",
    "                    dropout = dropout, \n",
    "                    device = device).to(device)\n",
    "\n",
    "model_BiLSTM = BiLSTM(input_size = input_size,\n",
    "                      hidden_size = hidden_size,\n",
    "                      sequence_length = sequence_length,\n",
    "                      num_layers = num_layers, \n",
    "                      dropout = dropout, \n",
    "                      device = device).to(device)\n",
    "\n",
    "model_BiGRU = BiGRU(input_size = input_size,\n",
    "                    hidden_size = hidden_size,\n",
    "                    sequence_length = sequence_length,\n",
    "                    num_layers = num_layers, \n",
    "                    dropout = dropout, \n",
    "                    device = device).to(device)\n",
    "\n",
    "model_seq2seq_RNN = RNN_encoder_decoder(input_size = input_size, \n",
    "                                        hidden_size = hidden_size,\n",
    "                                        num_layers = num_layers, \n",
    "                                        dropout = dropout,\n",
    "                                        device = device).to(device)\n",
    "\n",
    "model_seq2seq_LSTM = LSTM_encoder_decoder(input_size = input_size, \n",
    "                                         hidden_size = hidden_size,\n",
    "                                         num_layers = num_layers, \n",
    "                                         dropout = dropout,\n",
    "                                         device = device).to(device)\n",
    "\n",
    "model_seq2seq_GRU = GRU_encoder_decoder(input_size = input_size, \n",
    "                                        hidden_size = hidden_size,\n",
    "                                        num_layers = num_layers, \n",
    "                                        dropout = dropout,\n",
    "                                        device = device).to(device)\n",
    "\n",
    "model_seq2seq_BiRNN = BiRNN_encoder_decoder(input_size = input_size, \n",
    "                                            hidden_size = hidden_size,\n",
    "                                            num_layers = num_layers, \n",
    "                                            dropout = dropout,\n",
    "                                            device = device).to(device)\n",
    "\n",
    "model_seq2seq_BiLSTM = BiLSTM_encoder_decoder(input_size = input_size, \n",
    "                                              hidden_size = hidden_size,\n",
    "                                              num_layers = num_layers, \n",
    "                                              dropout = dropout,\n",
    "                                              device = device).to(device)\n",
    "\n",
    "model_seq2seq_BiGRU = BiGRU_encoder_decoder(input_size = input_size, \n",
    "                                            hidden_size = hidden_size,\n",
    "                                            num_layers = num_layers, \n",
    "                                            dropout = dropout,\n",
    "                                            device = device).to(device)\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "keys = ['RNN', 'LSTM', 'GRU', 'BiRNN', 'BiLSTM', 'BiGRU', \n",
    "        'seq2seq_RNN', 'seq2seq_LSTM', 'seq2seq_GRU', 'seq2seq_BiRNN', 'seq2seq_BiLSTM', 'seq2seq_BiGRU']\n",
    "\n",
    "models_list = [model_RNN, model_LSTM, model_GRU, \n",
    "              model_BiRNN, model_BiLSTM, model_BiGRU,\n",
    "              model_seq2seq_RNN, model_seq2seq_LSTM, model_seq2seq_GRU, \n",
    "              model_seq2seq_BiRNN, model_seq2seq_BiLSTM, model_seq2seq_BiGRU]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KDA_DA",
   "language": "python",
   "name": "kda_da"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
